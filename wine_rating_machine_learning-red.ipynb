{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbd4055-c013-465d-a0f3-b7e154123aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mjohn\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b991277f-14b6-495f-9d14-eb441cef2e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV files from Resources folder into DataFrames\n",
    "white_wine_df = pd.read_csv(Path(\"Resources/winequality-white.csv\"))\n",
    "white_wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7928edbe-4c89-4761-837b-57df2785ce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine_df = pd.read_csv(Path(\"Resources/winequality-red.csv\"))\n",
    "red_wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f543107-603e-4fa1-a7d7-bbbc1f3cd30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.176</td>\n",
       "      <td>52.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.170</td>\n",
       "      <td>51.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.341</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             7.4             0.700         0.00             1.9      0.076   \n",
       "1             7.8             0.880         0.00             2.6      0.098   \n",
       "2             7.8             0.760         0.04             2.3      0.092   \n",
       "3            11.2             0.280         0.56             1.9      0.075   \n",
       "4             7.4             0.700         0.00             1.9      0.076   \n",
       "5             7.4             0.660         0.00             1.8      0.075   \n",
       "6             7.9             0.600         0.06             1.6      0.069   \n",
       "7             7.3             0.650         0.00             1.2      0.065   \n",
       "8             7.8             0.580         0.02             2.0      0.073   \n",
       "9             7.5             0.500         0.36             6.1      0.071   \n",
       "10            6.7             0.580         0.08             1.8      0.097   \n",
       "11            7.5             0.500         0.36             6.1      0.071   \n",
       "12            5.6             0.615         0.00             1.6      0.089   \n",
       "13            7.8             0.610         0.29             1.6      0.114   \n",
       "14            8.9             0.620         0.18             3.8      0.176   \n",
       "15            8.9             0.620         0.19             3.9      0.170   \n",
       "16            8.5             0.280         0.56             1.8      0.092   \n",
       "17            8.1             0.560         0.28             1.7      0.368   \n",
       "18            7.4             0.590         0.08             4.4      0.086   \n",
       "19            7.9             0.320         0.51             1.8      0.341   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                  25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                  15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                  17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                  11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                  13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                  15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                  15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                   9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                  17.0                 102.0   0.9978  3.35       0.80   \n",
       "10                 15.0                  65.0   0.9959  3.28       0.54   \n",
       "11                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "12                 16.0                  59.0   0.9943  3.58       0.52   \n",
       "13                  9.0                  29.0   0.9974  3.26       1.56   \n",
       "14                 52.0                 145.0   0.9986  3.16       0.88   \n",
       "15                 51.0                 148.0   0.9986  3.17       0.93   \n",
       "16                 35.0                 103.0   0.9969  3.30       0.75   \n",
       "17                 16.0                  56.0   0.9968  3.11       1.28   \n",
       "18                  6.0                  29.0   0.9974  3.38       0.50   \n",
       "19                 17.0                  56.0   0.9969  3.04       1.08   \n",
       "\n",
       "    alcohol  quality   rating  \n",
       "0       9.4        5  average  \n",
       "1       9.8        5  average  \n",
       "2       9.8        5  average  \n",
       "3       9.8        6  average  \n",
       "4       9.4        5  average  \n",
       "5       9.4        5  average  \n",
       "6       9.4        5  average  \n",
       "7      10.0        7     good  \n",
       "8       9.5        7     good  \n",
       "9      10.5        5  average  \n",
       "10      9.2        5  average  \n",
       "11     10.5        5  average  \n",
       "12      9.9        5  average  \n",
       "13      9.1        5  average  \n",
       "14      9.2        5  average  \n",
       "15      9.2        5  average  \n",
       "16     10.5        7     good  \n",
       "17      9.3        5  average  \n",
       "18      9.0        4      bad  \n",
       "19      9.2        6  average  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add \"rating\" column\n",
    "def map_rating(quality):\n",
    "    if quality <= 4:\n",
    "        return \"bad\"\n",
    "    elif quality <= 6:\n",
    "        return \"average\"\n",
    "    else:\n",
    "        return \"good\"\n",
    "\n",
    "red_wine_df['rating'] = red_wine_df['quality'].apply(map_rating)\n",
    "\n",
    "red_wine_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cb29f-8c52-4227-9610-1e62065be53e",
   "metadata": {},
   "source": [
    "## Red Wine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ceec28-34fc-4279-9f58-e97c079e6097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity            96\n",
       "volatile acidity        143\n",
       "citric acid              80\n",
       "residual sugar           91\n",
       "chlorides               153\n",
       "free sulfur dioxide      60\n",
       "total sulfur dioxide    144\n",
       "density                 436\n",
       "pH                       89\n",
       "sulphates                96\n",
       "alcohol                  60\n",
       "quality                   6\n",
       "rating                    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "red_wine_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521b56ac-0f2b-4610-8596-4f48668246d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = red_wine_df[\"rating\"].values\n",
    "X = red_wine_df.drop([\"quality\", \"rating\"], axis='columns').values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6ce926-19be-45b1-b6c3-b727b0ec95e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['average', 'bad', 'good'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47594077-383e-4f4b-967d-6f04bbaca580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform target values\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f3fe6b-ed64-4818-8185-477897fde3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b0b8f-77a7-49a4-90e7-b5d10bcaef73",
   "metadata": {},
   "source": [
    "Compile, Train, Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e3ed473-6872-4f4b-af62-83cffa9d284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mjohn\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                240       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 947 (3.70 KB)\n",
      "Trainable params: 947 (3.70 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_input = len(X_train[0])\n",
    "hidden_layer_1 = 20\n",
    "hidden_layer_2 = 20\n",
    "hidden_layer_3 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_1, input_dim=num_input, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=7, activation=\"sigmoid\")\n",
    ")\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b94d50-04e2-42fe-a54a-438e9de148a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mjohn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc0b797-b9bd-4cd6-aaf3-d63a701cc4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\mjohn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mjohn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "38/38 [==============================] - 2s 4ms/step - loss: 1.4442 - accuracy: 0.6539\n",
      "Epoch 2/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8445 - accuracy: 0.8198\n",
      "Epoch 3/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.8198\n",
      "Epoch 4/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.8240\n",
      "Epoch 5/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8299\n",
      "Epoch 6/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8357\n",
      "Epoch 7/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8357\n",
      "Epoch 8/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8390\n",
      "Epoch 9/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8424\n",
      "Epoch 10/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8399\n",
      "Epoch 11/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8407\n",
      "Epoch 12/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8465\n",
      "Epoch 13/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8432\n",
      "Epoch 14/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8415\n",
      "Epoch 15/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8499\n",
      "Epoch 16/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8482\n",
      "Epoch 17/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8449\n",
      "Epoch 18/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8524\n",
      "Epoch 19/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8499\n",
      "Epoch 20/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8540\n",
      "Epoch 21/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8465\n",
      "Epoch 22/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8540\n",
      "Epoch 23/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8524\n",
      "Epoch 24/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8532\n",
      "Epoch 25/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8574\n",
      "Epoch 26/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8557\n",
      "Epoch 27/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8465\n",
      "Epoch 28/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8565\n",
      "Epoch 29/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8557\n",
      "Epoch 30/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8524\n",
      "Epoch 31/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8549\n",
      "Epoch 32/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8532\n",
      "Epoch 33/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8549\n",
      "Epoch 34/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8582\n",
      "Epoch 35/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8490\n",
      "Epoch 36/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8616\n",
      "Epoch 37/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8582\n",
      "Epoch 38/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8565\n",
      "Epoch 39/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3503 - accuracy: 0.8532\n",
      "Epoch 40/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8582\n",
      "Epoch 41/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8565\n",
      "Epoch 42/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8565\n",
      "Epoch 43/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8565\n",
      "Epoch 44/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8507\n",
      "Epoch 45/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8557\n",
      "Epoch 46/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8549\n",
      "Epoch 47/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3366 - accuracy: 0.8574\n",
      "Epoch 48/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8607\n",
      "Epoch 49/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8590\n",
      "Epoch 50/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8657\n",
      "Epoch 51/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8590\n",
      "Epoch 52/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8607\n",
      "Epoch 53/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8632\n",
      "Epoch 54/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8649\n",
      "Epoch 55/150\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8624\n",
      "Epoch 56/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8641\n",
      "Epoch 57/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8649\n",
      "Epoch 58/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8699\n",
      "Epoch 59/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8565\n",
      "Epoch 60/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8682\n",
      "Epoch 61/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8657\n",
      "Epoch 62/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8682\n",
      "Epoch 63/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3099 - accuracy: 0.8699\n",
      "Epoch 64/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8682\n",
      "Epoch 65/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8682\n",
      "Epoch 66/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8691\n",
      "Epoch 67/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8666\n",
      "Epoch 68/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3047 - accuracy: 0.8749\n",
      "Epoch 69/150\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.8716\n",
      "Epoch 70/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8741\n",
      "Epoch 71/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8674\n",
      "Epoch 72/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8682\n",
      "Epoch 73/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8707\n",
      "Epoch 74/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8716\n",
      "Epoch 75/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8741\n",
      "Epoch 76/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8699\n",
      "Epoch 77/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8716\n",
      "Epoch 78/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8749\n",
      "Epoch 79/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8732\n",
      "Epoch 80/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.8766\n",
      "Epoch 81/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8766\n",
      "Epoch 82/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8699\n",
      "Epoch 83/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8766\n",
      "Epoch 84/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8716\n",
      "Epoch 85/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8799\n",
      "Epoch 86/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8749\n",
      "Epoch 87/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8774\n",
      "Epoch 88/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8774\n",
      "Epoch 89/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.8799\n",
      "Epoch 90/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.8799\n",
      "Epoch 91/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8791\n",
      "Epoch 92/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8849\n",
      "Epoch 93/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8816\n",
      "Epoch 94/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8891\n",
      "Epoch 95/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2775 - accuracy: 0.8866\n",
      "Epoch 96/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8899\n",
      "Epoch 97/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8841\n",
      "Epoch 98/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8816\n",
      "Epoch 99/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8832\n",
      "Epoch 100/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.8874\n",
      "Epoch 101/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8916\n",
      "Epoch 102/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.8907\n",
      "Epoch 103/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8899\n",
      "Epoch 104/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.8941\n",
      "Epoch 105/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8932\n",
      "Epoch 106/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8957\n",
      "Epoch 107/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8932\n",
      "Epoch 108/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8882\n",
      "Epoch 109/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8982\n",
      "Epoch 110/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8941\n",
      "Epoch 111/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8941\n",
      "Epoch 112/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.8932\n",
      "Epoch 113/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8941\n",
      "Epoch 114/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.8874\n",
      "Epoch 115/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.8982\n",
      "Epoch 116/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.8949\n",
      "Epoch 117/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.8999\n",
      "Epoch 118/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.8932\n",
      "Epoch 119/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.9033\n",
      "Epoch 120/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8999\n",
      "Epoch 121/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9041\n",
      "Epoch 122/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2501 - accuracy: 0.8974\n",
      "Epoch 123/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.9016\n",
      "Epoch 124/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2435 - accuracy: 0.9091\n",
      "Epoch 125/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9033\n",
      "Epoch 126/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.9024\n",
      "Epoch 127/150\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2430 - accuracy: 0.9058\n",
      "Epoch 128/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.8991\n",
      "Epoch 129/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9041\n",
      "Epoch 130/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.9024\n",
      "Epoch 131/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9041\n",
      "Epoch 132/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2413 - accuracy: 0.9008\n",
      "Epoch 133/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9024\n",
      "Epoch 134/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9016\n",
      "Epoch 135/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9108\n",
      "Epoch 136/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9033\n",
      "Epoch 137/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9066\n",
      "Epoch 138/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9058\n",
      "Epoch 139/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9124\n",
      "Epoch 140/150\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2327 - accuracy: 0.9049\n",
      "Epoch 141/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9108\n",
      "Epoch 142/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9083\n",
      "Epoch 143/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9124\n",
      "Epoch 144/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9174\n",
      "Epoch 145/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9066\n",
      "Epoch 146/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9149\n",
      "Epoch 147/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.9166\n",
      "Epoch 148/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9158\n",
      "Epoch 149/150\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9099\n",
      "Epoch 150/150\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9191\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1692dda0-a618-4140-9f7d-843f8ddba5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.5384 - accuracy: 0.8525 - 279ms/epoch - 21ms/step\n",
      "Loss: 0.5384286642074585, Accuracy: 0.8525000214576721\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test_encoded,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e668911-9a71-4b0a-95ca-b462154bbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier module from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier model with n_neighbors = 3 \n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7bef506-83ac-4c90-9803-de197abf415e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6b22cd-0781-4e73-b9f7-3fe10b98ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb37c003-8bb3-4d48-97b1-42ca08646afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     average       0.89      0.93      0.91       336\n",
      "         bad       0.25      0.06      0.10        17\n",
      "        good       0.51      0.49      0.50        47\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.55      0.49      0.50       400\n",
      "weighted avg       0.82      0.84      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d506b44-f7b8-499e-8eb1-ece9e4408b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual     pred\n",
       "0  average  average\n",
       "1  average  average\n",
       "2  average  average\n",
       "3  average  average\n",
       "4  average  average"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Actual'] = y_test\n",
    "df['pred'] = y_pred\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1d05c6-7524-4a30-9867-661f662174b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate counts\n",
    "actual_counts = df['Actual'].value_counts().sort_index()\n",
    "pred_counts = df['pred'].value_counts().sort_index()\n",
    "\n",
    "# Create a new DataFrame for plotting\n",
    "plot_data = pd.DataFrame({'Actual': actual_counts, 'Pred': pred_counts})\n",
    "\n",
    "# Plot\n",
    "plot_data.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "# Customizing the plot\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)  # Keep the category names horizontal for readability\n",
    "plt.legend(title='Type')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fdbd921-523d-45ac-8a38-8f2d2847fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has successfully exported.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(Path(\"Output/red_wine_predictions.csv\"), index=False)\n",
    "print(\"DataFrame has successfully exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a279a93-dd72-4560-b31e-4066a4ca5fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
